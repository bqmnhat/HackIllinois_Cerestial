{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from rank_bm25 import BM25Okapi\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoilWaterCapacitySpider(scrapy.Spider):\n",
    "    name = \"soil_water_capacity\"\n",
    "\n",
    "    def __init__(self, query=\"tools or resources to help farmers assess their soil's water-holding capacity\", num_results=10, *args, **kwargs):\n",
    "        super(SoilWaterCapacitySpider, self).__init__(*args, **kwargs)\n",
    "        self.query = query\n",
    "        self.num_results = int(num_results)\n",
    "        self.urls = list(search(self.query, num_results=self.num_results))\n",
    "        self.corpus = []\n",
    "        self.results = []\n",
    "\n",
    "    def start_requests(self):\n",
    "        for url in self.urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        text = response.css(\"body ::text\").extract()\n",
    "        full_text = \" \".join(text)\n",
    "        self.corpus.append(full_text.lower().split())\n",
    "        self.results.append({\"url\": response.url, \"full_text\": full_text})\n",
    "\n",
    "        if len(self.corpus) == len(self.urls):\n",
    "            self.rank_and_yield()\n",
    "\n",
    "    def rank_and_yield(self):\n",
    "        bm25 = BM25Okapi(self.corpus)\n",
    "        tokenized_query = self.query.lower().split()\n",
    "        doc_scores = bm25.get_scores(tokenized_query)\n",
    "        ranked_results = sorted(zip(doc_scores, self.results), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        for score, result in ranked_results:\n",
    "            yield {\n",
    "                \"title\": response.css(\"title::text\").get() if (response := scrapy.Selector(text=requests.get(result['url']).text)) else \"No Title Found\", # added request to get response object for title.\n",
    "                \"url\": result[\"url\"],\n",
    "                \"score\": score,\n",
    "                \"text\": result[\"full_text\"],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 09:11:23 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-03-01 09:11:23 [scrapy.utils.log] INFO: Versions: lxml 5.3.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.13.2 (tags/v3.13.2:4f8bb39, Feb  4 2025, 15:23:48) [MSC v.1942 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.22631-SP0\n"
     ]
    }
   ],
   "source": [
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    from scrapy.crawler import CrawlerProcess\n",
    "    from scrapy.utils.project import get_project_settings\n",
    "\n",
    "    process = CrawlerProcess(get_project_settings())\n",
    "    process.crawl(SoilWaterCapacitySpider, query=\"soil water holding capacity practical guide\", num_results=5) # Example usage with different search terms and number of results.\n",
    "    process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
